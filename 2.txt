#A.import the necessary packages
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.optimizers import SGD

#B.Load the training and testing data (MNIST/CIFAR10)
data=tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test)=data.load_data()
x_train,x_test =x_train/255,x_test/255      # Covert all values between 0 to 1 
print(x_test.shape)
print(x_train.shape)

#C.Define the network architecture using Keras
model=tf.keras.models.Sequential([
tf.keras.layers.Flatten(input_shape=(28,28)),      # covert 2D into  1D  
tf.keras.layers.Dense(150,activation='relu'),      #  Dense Means Fully connected Network in Hiden Layer
tf.keras.layers.Dense(10,activation='softmax')     # classifying into 10 classes output have TEN neuron
])

#D.Train the model using SGD
sgd=SGD(0.02)    # is learning rate  0.02            #adam
model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history=model.fit(x_train, y_train,validation_data=(x_test,y_test),epochs=5) # Train the model

#E. Evaluate the network
test_loss,test_acc=model.evaluate(x_test,y_test)
plt.imshow(x_test[4])
prediction=model.predict(x_test)   #predict the data   
print(np.argmax(prediction[4]))   # print data depend on max probaiblites 

# F.Plot the training loss and accuracy
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot training accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

